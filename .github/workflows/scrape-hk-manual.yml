# This is a basic workflow that is manually triggered

name: scrape-hk-manual

# Controls when the workflow will run
on:
  [workflow_dispatch]
concurrency:
  group: scrape-and-schedule
  cancel-in-progress: false


# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "scrape"
  scrape:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    - name: checkout repo content
      uses: actions/checkout@v3       # checkout the repository content to github runner.
    - name: setup python
      uses: actions/setup-python@v5
      with:
          python-version: '3.12'
    - name: setup dependencies
      working-directory: ./mcd-scr-hk
      run: |
        pip3 install scrapy==2.11.2
        pip3 install pandas 
        pip3 install pytz
        pip3 install path
        pip3 install pathlib2
        pip3 install pyopenssl==22.0.0
        pip3 install cryptography==37.0.4 --ignore-installed
    - name: execute py script       # run mcd-scr-hk.py to get the latest data
      working-directory: ./mcd-scr-hk
      run: |
        scrapy crawl mcd-scr-hk
    - name: Commit and push if it changed
      run: |
        git config user.name "${GITHUB_ACTOR}"
        git config user.email "${GITHUB_ACTOR}@users.noreply.github.com"
        git add -A
        timestamp=$(date -u)
        if ! git diff-index --quiet HEAD; then
          git commit -m "Scraped: [${timestamp}] mcd-scr-hk (manual)" 
          git push "https://${GITHUB_ACTOR}:${TOKEN}@github.com/${GITHUB_REPOSITORY}.git" HEAD || exit 0
        fi

#EOF
