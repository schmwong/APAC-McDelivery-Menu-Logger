{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# A Simple Lightweight Script to Scrape McDelivery (Singapore) Menu\n\n---","metadata":{}},{"cell_type":"markdown","source":"### Import required libraries\n\n- **Requests** to send HTTP/1.1 requests\n- **BeautifulSoup** to parse the received content\n- **Pandas** to tabulate the filtered items\n- **DateTime** to add current date and time values\n- **re** to enable regular expressions","metadata":{}},{"cell_type":"code","source":"import requests as r\nfrom bs4 import BeautifulSoup as BS\nimport pandas as pd\nimport datetime as dt\nimport re","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:05:31.756925Z","iopub.execute_input":"2022-01-19T07:05:31.757662Z","iopub.status.idle":"2022-01-19T07:05:31.762343Z","shell.execute_reply.started":"2022-01-19T07:05:31.757611Z","shell.execute_reply":"2022-01-19T07:05:31.761522Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Declaring Request Headers to be Used\nThis will make the request seem to be from a normal browser","metadata":{}},{"cell_type":"code","source":"my_headers = {\n    \"Access-Control-Allow-Origin\":\"*\",\n    \"Access-Control-Allow-Methods\": \"GET\",\n    \"Access-Control-Allow-Headers\": \"Content-Type\",\n    \"Access-Control-Max-Age\": \"3600\",\n    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\", \n    \"Accept\": \"text/html,application/xhtml+xml,application/xml; q=0.9,image/webp,image/apng,*/*;q=0.8\"\n}\n              \nsession = r.Session()\n              \ncurrent_date = dt.datetime.now()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:05:31.763491Z","iopub.execute_input":"2022-01-19T07:05:31.763782Z","iopub.status.idle":"2022-01-19T07:05:31.780920Z","shell.execute_reply.started":"2022-01-19T07:05:31.763752Z","shell.execute_reply":"2022-01-19T07:05:31.780014Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Getting the Live Exchange Rate from XE","metadata":{}},{"cell_type":"code","source":"# Getting the correct XE webpage (all elements)\nXE = BS(session.get(\"https://www.xe.com/currencyconverter/convert/?Amount=1&From=SGD&To=USD\", headers=my_headers).content, \"lxml\")\n\n# Scraping the text from the selected element (CSS selector)\n# Extracting only the number from the text string and converting it to float value (decimal number) \n# findall() and select() methods return a list, indicate index [0] to extract the first element as a string value\nexchange_rate = float(re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", XE.select(\"p.result__BigRate-sc-1bsijpp-1.iGrAod\")[0].text)[0])\n\nprint(exchange_rate)\nprint(type(exchange_rate))","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:05:31.782153Z","iopub.execute_input":"2022-01-19T07:05:31.783032Z","iopub.status.idle":"2022-01-19T07:05:33.459412Z","shell.execute_reply.started":"2022-01-19T07:05:31.782984Z","shell.execute_reply":"2022-01-19T07:05:33.458346Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Parsing Items from Different Menus\n    \n   https://data36.com/scrape-multiple-web-pages-beautiful-soup-tutorial/\n    \n   https://hackersandslackers.com/scraping-urls-with-beautifulsoup/","metadata":{}},{"cell_type":"code","source":"URL_list = [     # Regular Menu\n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=21&catId=29\", # Promotion Meals \n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=21&catId=63\", # Chicken McCrispyÂ®\n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=21&catId=66\", # Sharing\n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=21&catId=30\", # Ala Carte & Value Meals\n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=21&catId=31\", # Sides\n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=21&catId=32\", # Desserts\n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=21&catId=33\", # Beverages\n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=21&catId=34\", # For the Family\n                 # Breakfast Menu \n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=22&catId=29\", # Promotion Meals\n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=22&catId=30\", # Breakfast & Value Meals\n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=22&catId=31\", # Sides\n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=22&catId=32\", # Desserts\n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=22&catId=33\", # Beverages\n    \"https://www.mcdelivery.com.sg/sg/browse/menu.html?daypartId=22&catId=34\"  # For the Family\n]\n\n\n\n# --------------------------------------\n# Parsing the data into Dictionary List\n# --------------------------------------\n\n# Initialising the dictionary list object\nproduct_list = []\n\n\n# Outer loop iterates through list of webpages\nfor url in URL_list:\n    response = session.get(url, headers=my_headers)\n    soup = BS(response.content, \"lxml\")\n    \n    # Inner loop iterates through elements on each webpage\n    for products in soup.select(\"div.product-card\"):\n        product = {}\n        product[\"Date\"] = current_date.strftime(\"%Y/%m/%d\")\n        product[\"Day\"] = current_date.strftime(\"%a\")\n        product[\"Territory\"] = \"Singapore\"\n        product[\"Menu Item\"] = products.select(\"h5.product-title\")[0].text\n        product[\"Price (SGD)\"] = float((re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\",products.select(\"span.starting-price\")[0].text)[0]))\n        product[\"Price (USD)\"] = round((product[\"Price (SGD)\"] * exchange_rate), 2)\n        product[\"Category\"] = soup.select(\"ol.breadcrumb > li.active\")[0].text\n        product[\"Menu\"] = soup.select(\"li.primary-menu-item.selected > a > span\")[0].text\n        product_list.append(product)\n        \n# print(product_list)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-01-19T07:05:33.462440Z","iopub.execute_input":"2022-01-19T07:05:33.463226Z","iopub.status.idle":"2022-01-19T07:05:45.755799Z","shell.execute_reply.started":"2022-01-19T07:05:33.463174Z","shell.execute_reply":"2022-01-19T07:05:45.754989Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Constructing the Dataframe (Table) and Saving to File\n\nhttps://pbpython.com/currency-cleanup.html","metadata":{}},{"cell_type":"code","source":"product_list_df = pd.DataFrame(product_list)\n\nprint(product_list_df)\n\ntimestamp = str(current_date.strftime(\"[%Y-%m-%d %H:%M:%S]\"))\nproduct_list_df.to_csv(str(timestamp + \" mcd-bs4-sg.csv\"), encoding=\"utf-8\", index=False)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-01-19T07:05:45.756968Z","iopub.execute_input":"2022-01-19T07:05:45.757184Z","iopub.status.idle":"2022-01-19T07:05:45.773201Z","shell.execute_reply.started":"2022-01-19T07:05:45.757159Z","shell.execute_reply":"2022-01-19T07:05:45.772320Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# name = h5.product-title\n# price = span.starting-price\n# category = div.clearfix li.active\n# menu = li.primary-menu-item.selected > a > span\n","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:05:45.774284Z","iopub.execute_input":"2022-01-19T07:05:45.774882Z","iopub.status.idle":"2022-01-19T07:05:45.782239Z","shell.execute_reply.started":"2022-01-19T07:05:45.774839Z","shell.execute_reply":"2022-01-19T07:05:45.781358Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#     name = soup.find_all(\"h5\", class_=\"product-title\") # returns list of elements\n#     name = [name.text for name in name] # for loop strips the tags off each element\n#     df_name = df_name.append(name, ignore_index=True) # returns dataframe of elements listed in a single column\n    \n#     price = soup.find_all(\"span\", class_=\"starting-price\")\n#     price = [price.text for price in price]\n#     df_price = df_price.append(price, ignore_index=True)\n    \n#     category = soup.select(\"ol.breadcrumb > li.active\")\n#     category = [category.text for category in category]\n#     df_category = df_category.append(category, ignore_index=True)\n    \n#     menu = soup.select(\"li.primary-menu-item.selected > a > span\")\n#     menu = [menu.text for menu in menu]\n#     df_menu = df_menu.append(menu, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:05:45.783272Z","iopub.execute_input":"2022-01-19T07:05:45.783880Z","iopub.status.idle":"2022-01-19T07:05:45.792994Z","shell.execute_reply.started":"2022-01-19T07:05:45.783851Z","shell.execute_reply":"2022-01-19T07:05:45.792145Z"},"trusted":true},"execution_count":14,"outputs":[]}]}